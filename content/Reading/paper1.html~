<html>
<head>

 <title>Deep Learning Human Mind for Automated Visual Classification</title>
	<meta name="date" content="10-19-2016" /> 
        <meta name="category" content="Reading" />
        <meta name="authors" content="Viral Parekh" />
        <meta name="summary" content="paper summary" />

</head>

<body>

<h3>Claim</h3>
<h3>Method</h3>

The work described in this paper relies on three key intuitions:
<ul>
<li>EEG signals recorded while a subject looks at an image convey feature-level
and cognitive-level information about the image content.</li>
<li>
A low-dimensional manifold within the multi-dimensional and temporally-
varying EEG signals exists and can be extracted to obtain a 1D represen-
tation which we refer to as
EEG features.</li>
<li>
EEG features
are assumed to mainly encode visual data, thus it is possible
to extract the corresponding image features for automated classification.
</li>
</ul>




Extracting features from EEG using LSTM encoder
<img src="{attach}/images/eeg_features_lstm.png" width="500px"/>

Pipeline for Automated visual classification
<img src="{attach}/images/pipeline_dlhmmodel.png" width="500px"/>

<table class="mytable1" >
<tr>
<td>Number of image categories</td>
<td>40 (subset of Imagenet)</td>
</tr>
<tr>
<td>Number of Subjects</td>
<td>7 (6 male + 1 female)</td>
</tr>
<tr>
<td>EEG device specification</td>
<td>32 channel, 250 Hz</td>
</tr>

</table>

<h3>Results</h3>

Classification of EEG features generated from LSTM network
<img src="{attach}/images/accuracy_for_eegfeatures.png" width="500px"/>

Automated visual classification: 
Accuracy on Caltech dataset.
<img src="{attach}/images/accuracy_caltech.png" width="500px"/>




</body>
</html>
